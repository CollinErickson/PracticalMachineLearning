---
title: "Practical Machine Learning Course Project"
author: "Collin"
date: "06/20/2014"
output: html_document
---



##Loading the data

First step was to load the entire training dataset provided and partition it into a training and testing set.

```{r,message=FALSE}
library(caret)
training <- read.csv('pml-training.csv')
testing <- read.csv('pml-testing.csv')
partition <- createDataPartition(y=training$classe,
                                 p=.7,list=F)
train1 <- training[partition,]
test1 <- training[-partition,]
```

## Random forest

I decided that I would use random forests as the learning method because it was one of the 
methods we learned about in the third week of the class and it sounded like it would likely 
give good results. 
I considered trying multiple methods and then using voting to pick my answer, but 
after seeing how long it took the code to run I settled with just one random forest.


##First attempt at training and prediction

My first thought was to try to train it using all the other columns for learning. 

``` {r,eval=F}
modFit <- train(classe ~ ., data=train1,method='rf')
```

After it ran for awhile without completing, I realized that it probably was too much data for prediction. I decided to be smarter about what data to use in the model.


## Selecting the data

To save on computation time I switched to using only 30% of the data for training, leaving the rest for testing. There were initially `r dim(training)[1]` datapoints provided for training, so 
using 30% for training the model is still plenty of data. Ideally I would have used closer 70% for training, but I wanted the program to run in reasonable time.


```{r,cache=TRUE,message=FALSE}
set.seed(3000)
partition <- createDataPartition(y=training$classe,
                                 p=.3,list=F)
train1 <- training[partition,]
test1 <- training[-partition,]
```


I tried to plot some of the variables against each other using the classe for the coloring.
From the first plot I made I realized that I probably would not need to use all the columns of data 
in order to get good classification. This plot shows just two of the variables plotted and it is 
clear that there is a relation between the variables and the classe.

``` {r,cache=T}
qplot(x=roll_belt,y=pitch_belt,col=classe,data=train1)
```

The first training I tried to do with this data was a random forest using only the four main variables 
associated with belt, `roll_belt, pitch_belt, yaw_belt, total_accel_belt`. 
This was arbitrary, I only used them because they were the first columns that looked 
like meaningful data. 

```{r,message=FALSE,cache=TRUE}
modFit <- train(classe ~ roll_belt + pitch_belt + yaw_belt + total_accel_belt, 
                data=train1, method='rf')
test1$predicted <- predict(modFit,test1)
test1$correct <- test1$classe==test1$predicted
confusionMatrix(test1$predicted,test1$classe)
```

This predicts the classe of the test variables with .849 accuracy, which is superb for using on 30% of the data and 
only four of the columns of the data. 
I decided to redo the model adding the four variables associated with dumbbell. This still omits most 
of the columns from the spreadsheet, but using all of the useful data would take far to long to calculate. 



                
```{r,message=FALSE,cache=TRUE}
modFit <- train(classe ~ roll_belt + pitch_belt + yaw_belt + total_accel_belt +
                roll_dumbbell+pitch_dumbbell+yaw_dumbbell + total_accel_dumbbell,
                data=train1,method='rf')
test1$predicted <- predict(modFit,test1)
test1$correct <- test1$classe==test1$predicted
confusionMatrix(test1$predicted,test1$classe)
```                
                
Not surprisingly, this model did even better getting accuracy around 93%.
I wanted to get the accuracy over 95%, so I decided to add eight more variables, 
the four associated with each of arm and forearm.


                
```{r,message=FALSE,cache=TRUE}
modFit <- train(classe ~ roll_belt + pitch_belt + yaw_belt + total_accel_belt +
                roll_dumbbell+pitch_dumbbell+yaw_dumbbell + total_accel_dumbbell + 
                roll_arm + pitch_arm + yaw_arm + total_accel_arm + 
                roll_forearm + pitch_forearm + yaw_forearm + total_accel_forearm, 
                data=train1,method='rf') 
test1$predicted <- predict(modFit,test1)
test1$correct <- test1$classe==test1$predicted
confusionMatrix(test1$predicted,test1$classe)
```         



## Submission

97% accuracy is fantastic so I decided that I would use this model for the assignment submission. I used the predict 
function to get predictions for the testing data.

```{r,cache=TRUE,message=FALSE}
predictions <- predict(modFit,testing)
predictions
```

When I submitted the files with these classifications, all of them were correct.


## Individual trees

We can try to look at an individual tree from the forest.

```{r,cache=TRUE,message=FALSE}
tree1 <- getTree(modFit$finalModel,k=1,labelVar=T)
dim(tree1)
head(tree1)
```

We see that the first tree has `r dim(tree1)[1]` different splits, which means that 
it is humongous. This large complexity means it would be hard to interpret and visualize 
even a single tree in the random forest.


## Conclusion

In conclusion, I used the random forest learning method in the `train` function. 
Computation time was a huge limitation, so I had to be careful about how much 
data I used and how many variables were used for learning.
I used 30% of the data for training, which is much smaller than typical, 
leaving 70% for testing the model.
I started using 4 variables for learning, and ended up using 16 because 
it gave a significant increase in testing performance.

When I used the learning model of the data set aside for testing, 
its accuracy was over 97%. Since there were 20 data points to categorize in the assignment,
I would have expected to get very few wrong, probably either zero or one.
The model worked perfectly and got all 20 correct.







